"""
Albert Heijn Bonus íŽ˜ì´ì§€ì—ì„œ ì‹œê°ì ìœ¼ë¡œ ë³´ì´ëŠ” ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
Playwrightì˜ locatorë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë Œë”ë§ëœ ìš”ì†Œì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
"""
import os
import json
import time
import re
from pathlib import Path
from playwright.sync_api import sync_playwright
from datetime import datetime, timedelta

# ë¸Œë¼ìš°ì € ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
LOCAL_BROWSERS_PATH = PROJECT_ROOT / "pw-browsers"
if LOCAL_BROWSERS_PATH.exists():
    os.environ['PLAYWRIGHT_BROWSERS_PATH'] = str(LOCAL_BROWSERS_PATH)

def scrape_ah_visual():
    """ì‹œê°ì ìœ¼ë¡œ ë Œë”ë§ëœ AH Bonus ìƒí’ˆ ì •ë³´ ì¶”ì¶œ"""
    url = "https://www.ah.nl/bonus"
    products = []
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080}
        )
        page = context.new_page()
        
        print(f"ðŸ” Albert Heijn Bonus íŽ˜ì´ì§€ ì ‘ì†: {url}")
        page.goto(url, timeout=60000)
        
        # íŽ˜ì´ì§€ ì™„ì „ ë¡œë”© ëŒ€ê¸°
        page.wait_for_load_state("networkidle")
        time.sleep(3)
        
        # ì¿ í‚¤ ë™ì˜
        try:
            btn = page.locator("button:has-text('Accepteren')").first
            if btn.is_visible(timeout=5000):
                print("ðŸª ì¿ í‚¤ ë™ì˜")
                btn.click()
                time.sleep(2)
        except:
            pass
        
        # JavaScript ë Œë”ë§ ì™„ë£Œ ëŒ€ê¸°
        page.wait_for_load_state("domcontentloaded")
        time.sleep(5)
        
        # ìŠ¤í¬ë¡¤í•˜ì—¬ ëª¨ë“  ìƒí’ˆ ë¡œë”©
        print("ðŸ“œ íŽ˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘...")
        last_height = page.evaluate("document.body.scrollHeight")
        for i in range(10):
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            time.sleep(2)
            new_height = page.evaluate("document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
            print(f"  ìŠ¤í¬ë¡¤ {i+1} ì™„ë£Œ")
        
        # ë§¨ ìœ„ë¡œ ëŒì•„ê°€ê¸°
        page.evaluate("window.scrollTo(0, 0)")
        time.sleep(2)
        
        # ìŠ¤í¬ë¦°ìƒ· ì €ìž¥
        screenshot_path = PROJECT_ROOT / "data" / "ah_visual_screenshot.png"
        page.screenshot(path=str(screenshot_path), full_page=True)
        print(f"ðŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ìž¥: {screenshot_path}")
        
        # ë‹¤ì–‘í•œ ì„ íƒìžë¡œ ìƒí’ˆ ì¹´ë“œ ì°¾ê¸°
        print("\nðŸ”Ž ìƒí’ˆ ì¹´ë“œ ê²€ìƒ‰ ì¤‘...")
        
        selectors_to_try = [
            # AH ì‚¬ì´íŠ¸ íŠ¹í™” ì„ íƒìž
            '[data-testhook*="product"]',
            '[data-testhook*="promotion"]',
            '[data-testhook*="bonus"]',
            '[class*="product-card"]',
            '[class*="ProductCard"]',
            '[class*="promotion-card"]',
            '[class*="PromotionCard"]',
            '[class*="bonus-card"]',
            '[class*="BonusCard"]',
            # ì¼ë°˜ì ì¸ ì„ íƒìž
            'article',
            '[role="article"]',
            '[class*="Card"]',
            '[class*="card"]',
            'a[href*="/producten/"]',
            'a[href*="/bonus/"]',
        ]
        
        found_elements = []
        for selector in selectors_to_try:
            try:
                elements = page.locator(selector).all()
                if elements and len(elements) > 0:
                    print(f"  âœ… '{selector}': {len(elements)}ê°œ ìš”ì†Œ")
                    for elem in elements[:5]:  # ì²˜ìŒ 5ê°œë§Œ ìƒ˜í”Œ
                        try:
                            text = elem.inner_text(timeout=1000)
                            if text and len(text) > 10:
                                found_elements.append({
                                    'selector': selector,
                                    'text': text[:200]
                                })
                        except:
                            pass
            except Exception as e:
                pass
        
        print(f"\nðŸ“¦ ë°œê²¬ëœ ìš”ì†Œ ìƒ˜í”Œ:")
        for i, elem in enumerate(found_elements[:10]):
            print(f"  {i+1}. [{elem['selector']}] {elem['text'][:100]}...")
        
        # íŽ˜ì´ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ì—ì„œ ìƒí’ˆ ì •ë³´ íŒ¨í„´ ì°¾ê¸°
        print("\nðŸ” íŽ˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ...")
        all_text = page.evaluate("document.body.innerText")
        
        # ê°€ê²© íŒ¨í„´ ì£¼ë³€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        price_pattern = r'([\w\s\-\']+)\s*â‚¬\s*(\d+)[,.](\d{2})'
        matches = re.findall(price_pattern, all_text)
        print(f"  ê°€ê²© íŒ¨í„´ ë§¤ì¹­: {len(matches)}ê°œ")
        
        for name, euros, cents in matches[:30]:
            name = name.strip()
            if len(name) > 3 and len(name) < 100:
                products.append({
                    'name': name,
                    'price': f"â‚¬{euros}.{cents}",
                    'supermarket': 'Albert Heijn'
                })
        
        # í• ì¸ íŒ¨í„´ (1+1, 2e halve prijs ë“±)
        discount_pattern = r'(\d+\+\d+|2e halve prijs|[0-9]+% korting)'
        discounts = re.findall(discount_pattern, all_text, re.IGNORECASE)
        print(f"  í• ì¸ íŒ¨í„´ ë°œê²¬: {len(discounts)}ê°œ - {set(discounts)}")
        
        # í…ìŠ¤íŠ¸ ë¼ì¸ë³„ ë¶„ì„
        lines = all_text.split('\n')
        print(f"  ì´ í…ìŠ¤íŠ¸ ë¼ì¸: {len(lines)}ê°œ")
        
        # ìƒí’ˆëª…ìœ¼ë¡œ ë³´ì´ëŠ” ë¼ì¸ ì¶”ì¶œ
        product_lines = []
        for i, line in enumerate(lines):
            line = line.strip()
            # ìƒí’ˆëª… ì¡°ê±´: ì ë‹¹í•œ ê¸¸ì´, ìˆ«ìžë¡œë§Œ ë˜ì–´ìžˆì§€ ì•ŠìŒ
            if 10 < len(line) < 80 and not line.isdigit():
                # ê°€ê²©ì´ ë°”ë¡œ ë‹¤ìŒ ì¤„ì— ìžˆëŠ”ì§€ í™•ì¸
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    if re.match(r'â‚¬?\s*\d+[,.]?\d*', next_line):
                        product_lines.append({
                            'name': line,
                            'price': next_line
                        })
        
        print(f"  ìƒí’ˆ-ê°€ê²© ìŒ ë°œê²¬: {len(product_lines)}ê°œ")
        for item in product_lines[:10]:
            print(f"    - {item['name']}: {item['price']}")
            products.append({
                'name': item['name'],
                'price': item['price'],
                'supermarket': 'Albert Heijn'
            })
        
        browser.close()
    
    # ì¤‘ë³µ ì œê±°
    seen = set()
    unique_products = []
    for p in products:
        key = p['name'].lower()
        if key not in seen:
            seen.add(key)
            unique_products.append(p)
    
    print(f"\nðŸŽ¯ ì´ {len(unique_products)}ê°œì˜ ê³ ìœ  ìƒí’ˆ ì¶”ì¶œ")
    
    # ê²°ê³¼ ì €ìž¥
    if unique_products:
        save_results(unique_products)
    
    return unique_products

def save_results(products):
    """ê²°ê³¼ ì €ìž¥"""
    today = datetime.now()
    if today.weekday() == 0:
        next_monday = today
    else:
        next_monday = today + timedelta(days=(7 - today.weekday()))
    next_sunday = next_monday + timedelta(days=6)
    
    # weekly_sales.json ì €ìž¥
    weekly_data = {
        'week_number': f"{next_monday.year}-{next_monday.isocalendar()[1]:02d}",
        'scraped_at': datetime.now().isoformat(),
        'total_products': len(products),
        'supermarkets': {'successful': ['Albert Heijn'], 'failed': []},
        'products': [
            {
                'supermarket': 'Albert Heijn',
                'product_name': p['name'],
                'price_info': p.get('price'),
                'start_date': next_monday.isoformat(),
                'end_date': next_sunday.isoformat(),
                'source': 'ah.nl/bonus',
                'scraped_at': datetime.now().isoformat()
            }
            for p in products
        ]
    }
    
    weekly_output = PROJECT_ROOT / "data" / "weekly_sales.json"
    with open(weekly_output, 'w', encoding='utf-8') as f:
        json.dump(weekly_data, f, ensure_ascii=False, indent=2)
    print(f"ðŸ“ weekly_sales.json ì €ìž¥ ì™„ë£Œ: {len(products)}ê°œ ìƒí’ˆ")

if __name__ == "__main__":
    products = scrape_ah_visual()
    
    print(f"\nðŸŽ‰ í¬ë¡¤ë§ ì™„ë£Œ! {len(products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘")
    
    # ìƒìœ„ 15ê°œ ìƒí’ˆ ì¶œë ¥
    print("\nðŸ“‹ ìƒìœ„ 15ê°œ ìƒí’ˆ:")
    for i, p in enumerate(products[:15], 1):
        print(f"  {i}. {p['name']} - {p.get('price', 'N/A')}")
    
    # íŠ¹ì • í‚¤ì›Œë“œ ê²€ìƒ‰
    keywords = ['speklap', 'kip', 'gehakt', 'kaas', 'melk', 'brood', 'pasta']
    print("\nðŸ”Ž í‚¤ì›Œë“œ ê²€ìƒ‰:")
    for kw in keywords:
        found = [p for p in products if kw.lower() in p['name'].lower()]
        if found:
            print(f"  âœ… '{kw}': {len(found)}ê°œ ë°œê²¬")
            for p in found[:2]:
                print(f"      - {p['name']} ({p.get('price', 'N/A')})")
        else:
            print(f"  âŒ '{kw}': ì—†ìŒ")
