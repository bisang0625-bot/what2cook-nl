# 🧠 스마트 스크래핑 스케줄러

Gemini API 사용량을 최소화하기 위해 마트별 세일 업데이트 요일을 분석하여 최적의 스크래핑 시점을 결정합니다.

## 📅 마트별 세일 시작일

| 마트 | 세일 시작일 | 스크래핑 추천 시점 |
|------|------------|------------------|
| **Albert Heijn** | 월요일 | 일요일 22:00 |
| **ALDI** | 월요일 | 일요일 22:00 |
| **Plus** | 월요일 | 일요일 22:00 |
| **Hoogvliet** | 월요일 | 일요일 22:00 |
| **Coop** | 월요일 | 일요일 22:00 |
| **Lidl** | 월요일 | 일요일 22:00 |
| **Jumbo** | 수요일 | 화요일 22:00 |
| **Dirk** | 수요일 | 화요일 22:00 |

## 🎯 최적 스크래핑 전략

### 1. 통합 스크래핑 (권장)
- **일요일 00:00 (자정)**: 모든 마트를 한 번에 스크래핑
- 세일 정보 업데이트 확인 후 실행
- 사용자가 월요일 아침에 미리 확인 가능
- 대부분의 마트가 월요일 시작이므로 효율적
- Jumbo와 Dirk도 미리 스크래핑 가능

### 2. 분리 스크래핑
- **일요일 00:00 (자정)**: 월요일 시작 마트들
- **화요일 00:00 (자정)**: 수요일 시작 마트들 (Jumbo, Dirk)

## 🚀 사용 방법

### 스크래핑 필요성 분석만 확인
```bash
python3 scraper/smart_scheduler.py --analyze
```

### 스마트 스크래핑 실행
```bash
python3 scraper/smart_scheduler.py
```
- 자동으로 스크래핑 필요 여부를 확인하고 실행
- 세일 정보 업데이트 확인 후 실행
- 불필요한 경우 스크래핑을 건너뜀

### 세일 정보 업데이트 대기
```bash
python3 scraper/smart_scheduler.py --wait-for-update
```
- 세일 정보가 업데이트될 때까지 대기 (최대 60분)
- 업데이트 확인 후 자동 실행

### 강제 실행
```bash
python3 scraper/smart_scheduler.py --force
```
- 분석 결과와 관계없이 강제 실행
- 세일 정보 업데이트 확인 건너뛰기

### 업데이트 확인 건너뛰기
```bash
python3 scraper/smart_scheduler.py --no-check-update
```
- 세일 정보 업데이트 확인 없이 실행

## ⚙️ 자동 실행 설정 (Cron)

### Cron Job 설정
```bash
bash scraper/setup_cron.sh
```

이 명령어는 다음 스케줄을 자동으로 설정합니다:
- **일요일 00:00 (자정)**: 월요일 시작 마트들 스크래핑 (세일 정보 업데이트 확인 후 실행)
- **화요일 00:00 (자정)**: 수요일 시작 마트들 스크래핑 (세일 정보 업데이트 확인 후 실행)

**장점:**
- 사용자가 아침에 미리 확인 가능
- 세일 정보가 실제로 업데이트된 후에만 실행
- 불필요한 API 호출 방지

### Cron Job 확인
```bash
crontab -l
```

### Cron Job 제거
```bash
crontab -e
# smart_scheduler.py 관련 라인 삭제
```

## 📊 스크래핑 필요성 판단 로직

스케줄러는 다음 조건을 확인합니다:

1. **이번 주 세일 데이터**
   - 세일 시작일이 2일 이내면 스크래핑 필요
   - 이미 최신 데이터가 있으면 스킵
   - 세일이 종료되었으면 스킵

2. **다음 주 세일 데이터**
   - 세일 시작일이 5일 이내면 스크래핑 필요
   - 최근 3일 이내 스크래핑되었으면 스킵

## 💡 API 사용량 절감 효과

### 기존 방식
- 매일 스크래핑: **주 7회** × 마트 수 = **매우 많은 API 호출**

### 스마트 스케줄러
- 주 2회 스크래핑: **주 2회** × 마트 수 = **약 70% 절감**
- 불필요한 스크래핑 자동 스킵: **추가 절감**

## 📝 로그 확인

자동 실행 시 로그는 다음 위치에 저장됩니다:
```
logs/cron_scraper.log
```

## 🔧 수동 실행

자동 실행이 설정되지 않은 경우, 수동으로 실행할 수 있습니다:

```bash
# 스크래핑 필요성 확인
python3 scraper/smart_scheduler.py --analyze

# 스마트 스크래핑 실행
python3 scraper/smart_scheduler.py
```

## ⚠️ 주의사항

1. **시간대**: Cron job은 서버의 로컬 시간대를 사용합니다
2. **네트워크**: 스크래핑 시 안정적인 인터넷 연결 필요
3. **API 키**: `.env` 파일에 `GEMINI_API_KEY`가 설정되어 있어야 합니다
