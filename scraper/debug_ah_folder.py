"""
Reclamefolder.nlì—ì„œ ì‹¤ì œ Albert Heijn í´ë” í˜ì´ì§€ ë¶„ì„
"""
import os
from pathlib import Path
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import re
import time
import json

# ë¸Œë¼ìš°ì € ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
LOCAL_BROWSERS_PATH = PROJECT_ROOT / "pw-browsers"
if LOCAL_BROWSERS_PATH.exists():
    os.environ['PLAYWRIGHT_BROWSERS_PATH'] = str(LOCAL_BROWSERS_PATH)

def debug_ah_folder():
    # ì‹¤ì œ Albert Heijn í´ë” í˜ì´ì§€ URL
    url = "https://www.reclamefolder.nl/f/folders/68451/"
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        )
        page = context.new_page()
        
        print(f"ğŸ” Albert Heijn í´ë” í˜ì´ì§€ ì ‘ì†: {url}")
        page.goto(url, timeout=60000)
        page.wait_for_load_state("networkidle")
        
        # ì¿ í‚¤ ë™ì˜
        try:
            cookie_btn = page.get_by_role("button", name=re.compile("allow|accept|akkoord|agree", re.IGNORECASE))
            if cookie_btn.count() > 0 and cookie_btn.first.is_visible():
                print("ğŸª ì¿ í‚¤ ë™ì˜")
                cookie_btn.first.click()
                time.sleep(2)
        except:
            pass
        
        # ì¶”ê°€ ëŒ€ê¸°
        time.sleep(3)
        
        # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        screenshot_path = PROJECT_ROOT / "data" / "ah_folder_screenshot.png"
        page.screenshot(path=str(screenshot_path), full_page=True)
        print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}")
        
        # HTML ì €ì¥
        content = page.content()
        html_path = PROJECT_ROOT / "data" / "ah_folder_page.html"
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ“„ HTML ì €ì¥: {html_path}")
        
        # í˜ì´ì§€ ì œëª© í™•ì¸
        title = page.title()
        print(f"ğŸ“° í˜ì´ì§€ ì œëª©: {title}")
        
        # ìƒí’ˆ ì •ë³´ ê²€ìƒ‰
        soup = BeautifulSoup(content, 'html.parser')
        all_text = soup.get_text().lower()
        
        # ë„¤ëœë€ë“œ ìŠˆí¼ë§ˆì¼“ ìƒí’ˆëª… í‚¤ì›Œë“œ ê²€ìƒ‰
        keywords = ['speklappen', 'kip', 'varken', 'rund', 'gehakt', 'kaas', 'melk', 'brood', 
                    'pasta', 'druiven', 'vis', 'vlees', 'groente']
        print("\nğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰:")
        found_keywords = []
        for kw in keywords:
            if kw.lower() in all_text:
                print(f"  âœ… '{kw}' ë°œê²¬!")
                found_keywords.append(kw)
            else:
                print(f"  âŒ '{kw}' ì—†ìŒ")
        
        # ê°€ê²© íŒ¨í„´ ê²€ìƒ‰
        price_pattern = re.findall(r'â‚¬\s*[\d,.]+', content)
        print(f"\nğŸ’° ë°œê²¬ëœ ê°€ê²© íŒ¨í„´: {len(price_pattern)}ê°œ")
        if price_pattern:
            print(f"  ì˜ˆì‹œ: {price_pattern[:5]}")
        
        browser.close()
        
    print("\nâœ… ë””ë²„ê·¸ ì™„ë£Œ!")

if __name__ == "__main__":
    debug_ah_folder()
