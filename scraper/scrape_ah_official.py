"""
Albert Heijn ê³µì‹ Bonus í˜ì´ì§€ í¬ë¡¤ëŸ¬
ì‹¤ì œ Bonus í˜ì´ì§€ì—ì„œ ë‹¤ìŒ ì£¼ ì„¸ì¼ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ìˆ˜ì§‘
"""
import os
import json
import time
from pathlib import Path
from playwright.sync_api import sync_playwright
from datetime import datetime, timedelta

# í™˜ê²½ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
LOCAL_BROWSERS_PATH = PROJECT_ROOT / "pw-browsers"
if LOCAL_BROWSERS_PATH.exists():
    os.environ['PLAYWRIGHT_BROWSERS_PATH'] = str(LOCAL_BROWSERS_PATH)

def get_next_monday():
    """ë‹¤ìŒ ì›”ìš”ì¼ ë‚ ì§œ ê³„ì‚°"""
    today = datetime.now()
    if today.weekday() == 0:
        return today
    return today + timedelta(days=(7 - today.weekday()))

def scrape_ah_bonus():
    """Albert Heijn Bonus í˜ì´ì§€ í¬ë¡¤ë§"""
    print("\nğŸ›’ Albert Heijn ê³µì‹ Bonus í˜ì´ì§€ í¬ë¡¤ë§")
    print("="*60)
    
    products = []
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)  # ë””ë²„ê·¸ìš© headless=False
        context = browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        )
        
        page = context.new_page()
        
        # Albert Heijn Bonus í˜ì´ì§€
        url = "https://www.ah.nl/bonus"
        print(f"ğŸ”— {url}")
        page.goto(url, timeout=60000)
        
        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        page.wait_for_load_state("networkidle")
        time.sleep(5)
        
        # ì¿ í‚¤ ë™ì˜
        try:
            cookie_selectors = [
                'button:has-text("Accepteren")',
                'button:has-text("Accept")',
                '[data-testid="consent-accept"]'
            ]
            for selector in cookie_selectors:
                try:
                    button = page.locator(selector).first
                    if button.is_visible():
                        button.click()
                        time.sleep(2)
                        break
                except:
                    pass
        except:
            pass
        
        print("ğŸ“¸ í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ì¤‘...")
        screenshot_dir = PROJECT_ROOT / "data" / "screenshots"
        screenshot_dir.mkdir(exist_ok=True)
        page.screenshot(path=str(screenshot_dir / "ah-bonus-debug.png"), full_page=True)
        
        print("ğŸ” ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì¤‘...")
        
        # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„
        try:
            # ë°©ë²• 1: ìƒí’ˆ ì¹´ë“œ ì°¾ê¸°
            product_cards = page.locator('[data-testhook="product-card"], article, [class*="product"]').all()
            print(f"ë°œê²¬ëœ ìš”ì†Œ: {len(product_cards)}ê°œ")
            
            for i, card in enumerate(product_cards[:30]):  # ìµœëŒ€ 30ê°œ
                try:
                    text = card.inner_text()
                    if len(text) > 10:  # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸
                        # ìƒí’ˆëª… ì¶”ì¶œ (ê°„ë‹¨í•˜ê²Œ)
                        lines = [line.strip() for line in text.split('\n') if line.strip()]
                        if lines:
                            name = lines[0]
                            price = None
                            discount = None
                            
                            # ê°€ê²© ì°¾ê¸°
                            for line in lines:
                                if 'â‚¬' in line or 'euro' in line.lower():
                                    price = line
                                if '+' in line or 'korting' in line.lower() or 'gratis' in line.lower():
                                    discount = line
                            
                            if name and len(name) > 3:
                                products.append({
                                    'name': name,
                                    'price': price,
                                    'discount': discount
                                })
                                print(f"  {i+1}. {name}")
                except:
                    continue
        except Exception as e:
            print(f"âš ï¸ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        
        # HTML ì €ì¥ (ë””ë²„ê·¸ìš©)
        html_path = PROJECT_ROOT / "data" / "ah_bonus_debug.html"
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(page.content())
        print(f"ğŸ’¾ HTML ì €ì¥: {html_path.name}")
        
        input("\nâ¸ï¸  ë¸Œë¼ìš°ì €ë¥¼ í™•ì¸í•˜ì„¸ìš”. ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        
        browser.close()
    
    return products

def save_products(products):
    """ìƒí’ˆ ì €ì¥"""
    next_monday = get_next_monday()
    next_sunday = next_monday + timedelta(days=6)
    
    data = {
        'week_number': f"{next_monday.year}-{next_monday.isocalendar()[1]:02d}",
        'sale_period': f"{next_monday.strftime('%Y-%m-%d')} ~ {next_sunday.strftime('%Y-%m-%d')}",
        'scraped_at': datetime.now().isoformat(),
        'total_products': len(products),
        'supermarkets': {
            'successful': ['Albert Heijn'],
            'failed': []
        },
        'products': [
            {
                'supermarket': 'Albert Heijn',
                'product_name': p['name'],
                'price_info': p.get('price'),
                'discount_info': p.get('discount'),
                'start_date': next_monday.isoformat(),
                'end_date': next_sunday.isoformat(),
                'source': 'ah.nl/bonus (official)',
                'scraped_at': datetime.now().isoformat()
            }
            for p in products
        ]
    }
    
    output = PROJECT_ROOT / "data" / "weekly_sales.json"
    with open(output, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ {len(products)}ê°œ ìƒí’ˆ ì €ì¥ ì™„ë£Œ")

if __name__ == "__main__":
    products = scrape_ah_bonus()
    
    if products:
        print(f"\nâœ… {len(products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
        save_products(products)
    else:
        print("\nâš ï¸ ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
        print("HTMLê³¼ ìŠ¤í¬ë¦°ìƒ·ì„ í™•ì¸í•˜ì—¬ í˜ì´ì§€ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì„¸ìš”")
