"""
ê¸°ë³¸ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤
ê° ë§ˆíŠ¸ì˜ strategyì— ë”°ë¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í¬ë¡¤ë§
"""
import os
import time
from pathlib import Path
from playwright.sync_api import sync_playwright, Page
from datetime import datetime, timedelta
from .store_config import SCRAPING_CONFIG

class BaseScraper:
    """ìŠˆí¼ë§ˆì¼“ í¬ë¡¤ëŸ¬ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, store_config: dict, project_root: Path):
        self.config = store_config
        self.name = store_config['name']
        self.url = store_config['url']
        self.strategy = store_config['strategy']
        self.selectors = store_config['selectors']
        self.project_root = project_root
        
        # Playwright ë¸Œë¼ìš°ì € ê²½ë¡œ ì„¤ì •
        local_browsers = project_root / "pw-browsers"
        if local_browsers.exists():
            os.environ['PLAYWRIGHT_BROWSERS_PATH'] = str(local_browsers)
    
    def scrape(self) -> list:
        """ë©”ì¸ í¬ë¡¤ë§ ë©”ì„œë“œ"""
        print(f"\n{'='*70}")
        print(f"ğŸ›’ {self.name} í¬ë¡¤ë§ ì‹œì‘")
        print(f"{'='*70}")
        print(f"ğŸ”— URL: {self.url}")
        print(f"ğŸ“‹ Strategy: {self.strategy}")
        
        products = []
        
        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(
                    headless=SCRAPING_CONFIG['headless']
                )
                context = browser.new_context(
                    user_agent=SCRAPING_CONFIG['user_agent'],
                    viewport=SCRAPING_CONFIG['viewport']
                )
                
                page = context.new_page()
                
                # 1. í˜ì´ì§€ ë¡œë“œ
                print("ğŸ“„ í˜ì´ì§€ ë¡œë”© ì¤‘...")
                page.goto(self.url, timeout=SCRAPING_CONFIG['timeout'])
                page.wait_for_load_state("networkidle")
                time.sleep(SCRAPING_CONFIG['wait_after_load'])
                
                # 2. ì¿ í‚¤ ë™ì˜ ì²˜ë¦¬
                self._handle_cookie_consent(page)
                
                # 3. Strategyë³„ ì²˜ë¦¬
                if self.strategy == "direct_url":
                    print("âœ… Direct URL - ë°”ë¡œ ë°ì´í„° ìˆ˜ì§‘")
                    products = self._scrape_direct(page)
                    
                elif self.strategy == "click_next_week":
                    print("ğŸ–±ï¸  'Volgende week' ë²„íŠ¼ í´ë¦­ ì‹œë„...")
                    if self._click_next_week_button(page):
                        products = self._scrape_direct(page)
                    else:
                        print("âš ï¸ ë‹¤ìŒ ì£¼ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘...")
                        products = self._scrape_direct(page)
                        
                elif self.strategy == "click_category":
                    print("ğŸ–±ï¸  ì¹´í…Œê³ ë¦¬ ë²„íŠ¼ í´ë¦­ ì‹œë„...")
                    if self._click_category_button(page):
                        products = self._scrape_direct(page)
                    else:
                        print("âš ï¸ ì¹´í…Œê³ ë¦¬ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        products = self._scrape_direct(page)
                        
                elif self.strategy == "default":
                    print("âœ… Default - ë°”ë¡œ ë°ì´í„° ìˆ˜ì§‘")
                    products = self._scrape_direct(page)
                
                # 4. ìŠ¤í¬ë¦°ìƒ· ì €ì¥ (ë””ë²„ê·¸ìš©)
                self._save_screenshot(page)
                
                browser.close()
                
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}")
            return []
        
        if products:
            print(f"âœ… {len(products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ!")
        else:
            print(f"âš ï¸ ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        return products
    
    def _handle_cookie_consent(self, page: Page):
        """ì¿ í‚¤ ë™ì˜ ì²˜ë¦¬"""
        try:
            cookie_texts = [
                'accepteren', 'accept', 'akkoord', 'agree', 
                'toestaan', 'alle cookies'
            ]
            
            for text in cookie_texts:
                try:
                    buttons = page.get_by_role("button", name=text).all()
                    for button in buttons:
                        if button.is_visible():
                            button.click()
                            time.sleep(2)
                            print("ğŸª ì¿ í‚¤ ë™ì˜ ì™„ë£Œ")
                            return
                except:
                    pass
        except:
            pass
    
    def _click_next_week_button(self, page: Page) -> bool:
        """'ë‹¤ìŒ ì£¼' ë²„íŠ¼ í´ë¦­"""
        selectors = self.selectors.get('next_week_btn', '').split(', ')
        
        for selector in selectors:
            try:
                # CSS selector ì‹œë„
                element = page.locator(selector).first
                if element.count() > 0 and element.is_visible():
                    element.click()
                    time.sleep(SCRAPING_CONFIG['wait_after_click'])
                    print(f"  âœ… ë²„íŠ¼ í´ë¦­ ì„±ê³µ: {selector}")
                    return True
            except:
                pass
        
        # í…ìŠ¤íŠ¸ë¡œ ì§ì ‘ ì°¾ê¸°
        try:
            texts = ['Volgende week', 'volgende week', 'Volgende']
            for text in texts:
                element = page.get_by_text(text, exact=False).first
                if element.count() > 0 and element.is_visible():
                    element.click()
                    time.sleep(SCRAPING_CONFIG['wait_after_click'])
                    print(f"  âœ… ë²„íŠ¼ í´ë¦­ ì„±ê³µ: '{text}'")
                    return True
        except:
            pass
        
        return False
    
    def _click_category_button(self, page: Page) -> bool:
        """ì¹´í…Œê³ ë¦¬ ë²„íŠ¼ í´ë¦­ (Lidl ë“±)"""
        selectors = self.selectors.get('category_btn', '').split(', ')
        
        for selector in selectors:
            try:
                element = page.locator(selector).first
                if element.count() > 0 and element.is_visible():
                    element.click()
                    time.sleep(SCRAPING_CONFIG['wait_after_click'])
                    print(f"  âœ… ì¹´í…Œê³ ë¦¬ í´ë¦­ ì„±ê³µ: {selector}")
                    return True
            except:
                pass
        
        return False
    
    def _scrape_direct(self, page: Page) -> list:
        """ì‹¤ì œ ìƒí’ˆ ë°ì´í„° ìˆ˜ì§‘"""
        products = []
        
        # ëŒ€ê¸°í•  ìš”ì†Œê°€ ìˆìœ¼ë©´ ëŒ€ê¸°
        if 'wait_for' in self.config:
            try:
                page.wait_for_selector(
                    self.config['wait_for'], 
                    timeout=10000
                )
            except:
                print("  âš ï¸ ëŒ€ê¸° ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìƒí’ˆ ì¹´ë“œ ì°¾ê¸°
        product_selectors = self.selectors.get('product_card', '').split(', ')
        product_cards = []
        
        for selector in product_selectors:
            try:
                cards = page.locator(selector).all()
                if len(cards) > 0:
                    product_cards = cards
                    print(f"  ğŸ“¦ {len(cards)}ê°œ ìƒí’ˆ ì¹´ë“œ ë°œê²¬: {selector}")
                    break
            except:
                pass
        
        if not product_cards:
            print("  âš ï¸ ìƒí’ˆ ì¹´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ê° ìƒí’ˆ ì¹´ë“œì—ì„œ ì •ë³´ ì¶”ì¶œ
        for i, card in enumerate(product_cards[:50], 1):  # ìµœëŒ€ 50ê°œ
            try:
                product = self._extract_product_info(card)
                if product and product.get('name'):
                    product['supermarket'] = self.name
                    products.append(product)
                    print(f"  {i}. {product['name'][:50]}")
            except Exception as e:
                continue
        
        return products
    
    def _extract_product_info(self, card) -> dict:
        """ê°œë³„ ìƒí’ˆ ì¹´ë“œì—ì„œ ì •ë³´ ì¶”ì¶œ"""
        product = {
            'name': None,
            'price': None,
            'discount': None
        }
        
        # ìƒí’ˆëª… ì¶”ì¶œ
        title_selectors = self.selectors.get('title', '').split(', ')
        for selector in title_selectors:
            try:
                element = card.locator(selector).first
                if element.count() > 0:
                    product['name'] = element.inner_text().strip()
                    break
            except:
                pass
        
        # ìƒí’ˆëª…ì„ ëª» ì°¾ìœ¼ë©´ ì¹´ë“œ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì²« ì¤„ ì‚¬ìš©
        if not product['name']:
            try:
                text = card.inner_text().strip()
                lines = [line.strip() for line in text.split('\n') if line.strip()]
                if lines:
                    product['name'] = lines[0]
            except:
                pass
        
        # ê°€ê²© ì¶”ì¶œ
        price_selectors = self.selectors.get('price', '').split(', ')
        for selector in price_selectors:
            try:
                element = card.locator(selector).first
                if element.count() > 0:
                    product['price'] = element.inner_text().strip()
                    break
            except:
                pass
        
        # í• ì¸ ì •ë³´ ì¶”ì¶œ
        discount_selectors = self.selectors.get('discount', '').split(', ')
        for selector in discount_selectors:
            try:
                element = card.locator(selector).first
                if element.count() > 0:
                    product['discount'] = element.inner_text().strip()
                    break
            except:
                pass
        
        return product
    
    def _save_screenshot(self, page: Page):
        """ìŠ¤í¬ë¦°ìƒ· ì €ì¥ (ë””ë²„ê·¸ìš©)"""
        try:
            screenshot_dir = self.project_root / "data" / "screenshots"
            screenshot_dir.mkdir(parents=True, exist_ok=True)
            
            filename = f"{self.name.lower().replace(' ', '_')}_official.png"
            page.screenshot(path=str(screenshot_dir / filename), full_page=True)
            print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
        except:
            pass
